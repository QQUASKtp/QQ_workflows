{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Cloud Classification for urban cover mapping\n",
    "----------------------\n",
    "\n",
    "The following workflow demonstrates point cloud classification using the Computational Geometry Algorithms Library This assumes basic knowledge of python and GIS usage. Compared to the other point cloud algorithms, this method is a little more sophisticated and could be applied to get a quick (i.e. minutes > hour generating training)  characterisation of an environment with relatively little training collection. \n",
    "\n",
    "The paper associated is found here:\n",
    "\n",
    "https://hal.inria.fr/file/index/docid/759265/filename/ijcv_2012.pdf\n",
    "\n",
    "The functions etc. of this workflow can be found here:\n",
    "\n",
    "https://doc.cgal.org/latest/Classification/index.html\n",
    "\n",
    "The algorithm is based on the computation of a set of pointwise geometric attributes (such as planarity, local elevation, etc.). Each type (heath, shrubs, trees) is defined as a linear combination of these attributes. Classification is achieved by minimizing an energy over the input point cloud by selecting, for each point, the classification type that gives the best score. Global regularization is performed by using a graph-cut algorithm (alpha expansion).\n",
    "\n",
    "This dataset is a point cloud of the Cors Fochno SSSI building derived via SfM. The colours will look unusual as they represent the Red, Red-Edge & Near-Infra-Red bands repspectively, which are more informative for distinguising vegetation types. You will get used to it! \n",
    "\n",
    "Dependencies:\n",
    "\n",
    "The code depends on the CGAL library, which can be installed most easily via anaconda or compiled from source.\n",
    "\n",
    "Assumed knowledge:\n",
    "\n",
    "Basic GIS, image processing, remote sensing, python and command line use\n",
    "\n",
    "Remember to query function args open a new cell (the plus icon) and write the function with a question mark - i.e\n",
    "\n",
    "function?\n",
    "\n",
    "As the python CGAL API is a swig binding, docstring on functions may not be very informative. This workflow can also of course be easily executed directly using the C++ api.  \n",
    "\n",
    "The lines of code have been written with readability in mind making each step as clear as possible, hence they are obviously not the briefest/most efficient way of doing things!\n",
    "\n",
    "Data\n",
    "\n",
    "The data is temporarily found in the QQ/KTP google drive.\n",
    "\n",
    "The file required is Llandinam.zip - extract this somewhere appropriate and change dir to this folder.\n",
    "\n",
    "https://drive.google.com/drive/folders/1vMV-ptTZ7WVrUi6VygYHbmFjXYE39QKl?usp=sharing\n",
    "\n",
    "This contains:\n",
    "\n",
    "- Llandinam.ply\n",
    "\n",
    "\n",
    "**You will need a machine with plenty of cores and RAM to process this speedily.** \n",
    "\n",
    "\n",
    "\n",
    "The training labels are pre-made in the integer field \"label\". If you wish to create your own, the labels must be contiguous signed integers where -1 is nodata, 0,1,2,3 are the classes. This can be done in Cloud Compare (CC) by segmenting the point cloud and labeling with a scalar field. Better still, the whole operation can be run from the CGAL Polyhedron_3 demo GUI, if you follow the compilation instructions for this.\n",
    "\n",
    "The CorsFochno.ply will look like this in CC.\n",
    "\n",
    "<img src=\"Figures/Llandinam.png\" style=\"height:500px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module imports \n",
    "----------------------\n",
    "The cgal lib can be found here with several ways to install. \n",
    "\n",
    "https://www.cgal.org/\n",
    "\n",
    "The easiest is the official cgal repositories or anaconda. \n",
    "Install plyfile via pip in the same conda environment.  \n",
    "\n",
    "https://www.cgal.org/download.html\n",
    "\n",
    "https://anaconda.org/conda-forge/cgal\n",
    "\n",
    "However this will not include the demos etc. See the repo README for some info on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CGAL.CGAL_Kernel import Point_3\n",
    "from CGAL.CGAL_Kernel import Vector_3\n",
    "from CGAL.CGAL_Point_set_3 import Point_set_3\n",
    "from CGAL.CGAL_Classification import *\n",
    "from plyfile import PlyData\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and return the no of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incloud = 'Llandinam.ply'\n",
    "points = Point_set_3(incloud)\n",
    "print(points.size(), \"points read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels\n",
    "\n",
    "This will enable us to extract the classes in the correct order for CGAL, though they could be predefined. This uses the ply header and pulls out the relevant text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PlyData.read(incloud)\n",
    "clList = pf.comments\n",
    "\n",
    "# apologies for this ugly code!!!\n",
    "if clList[0] == \"Generated by the CGAL library\":\n",
    "    clss = clList[2:len(clList)]\n",
    "    classes = [c.split()[2] for c in clss]\n",
    "    classes.pop(0)\n",
    "    del clss, clList\n",
    "\n",
    "labels = Label_set()\n",
    "for c in classes:\n",
    "    labels.add(c)\n",
    "    \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to set different names here is how it is done. Uncomment this and set how you'd prefer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = Label_set()\n",
    "\n",
    "\n",
    "#ground = labels.add(\"ground\") # 0\n",
    "\n",
    "#trees = labels.add(\"trees\") # 1\n",
    "\n",
    "#roof = labels.add(\"roof\") # 2\n",
    "\n",
    "#facade = labels.add(\"facade\") # 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation\n",
    "\n",
    "The following lines generate point features based on the existing fields of the point cloud, eigen values and spatial filters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Feature_set()\n",
    "generator = Point_set_feature_generator(points, 5)\n",
    "\n",
    "features.begin_parallel_additions()\n",
    "generator.generate_point_based_features(features)\n",
    "\n",
    "if points.has_normal_map():\n",
    "    generator.generate_normal_based_features(features, points.normal_map())\n",
    "\n",
    "\n",
    "if points.has_int_map(\"red\") and points.has_int_map(\"green\") and points.has_int_map(\"blue\"):\n",
    "    generator.generate_color_based_features(features,\n",
    "                                            points.int_map(\"red\"),\n",
    "                                            points.int_map(\"green\"),\n",
    "                                            points.int_map(\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the example labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = points.int_map(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we train the classifier and save the model for further use if required (and effective enough!). \n",
    "\n",
    "If you wish to label the training yourself - you will need either Cloud Compare or the CGAL Polyhedron_3 demo.\n",
    "\n",
    "Cloud Compare will facillitate this by segment by a bit of a hacky workaround where you will have to segment bits of the cloud for each class, give them a constant scalar field (the class name) then merge them back together. This is not ideal but works! Here is a link to the tool basics.\n",
    "\n",
    "https://www.cloudcompare.org/doc/wiki/index.php?title=Interactive_Segmentation_Tool\n",
    "\n",
    "Better still, the CGAL_Polyhedron demo can be compliled from the main library but it may become a character building experience doing so. If successful you will have a QT-based GUI to label the data. Otherwise, there a few point labelling applications out there FOSS or proprietary but may not output the correct datatypes for CGAL!\n",
    "\n",
    "Anyway.....\n",
    "\n",
    "First we must create an path for the model to be saved - please insert your own. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outmodel = \"testrf.gz\"\n",
    "#outmodel = \"/path/to/my/model.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = points.add_int_map(\"training\")\n",
    "for idx in points.indices():\n",
    "    training.set(idx, classification.get(idx))\n",
    "\n",
    "print(\"Training random forest classifier...\")\n",
    "classifier = ETHZ_Random_forest_classifier(labels, features)\n",
    "classifier.train(points.range(training), num_trees=50, max_depth=30)\n",
    "\n",
    "print(\"Saving classifier's trained configuration...\")\n",
    "classifier.save_configuration(outmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and output\n",
    "\n",
    "Here we classify via a few different methods to see the merits/pitfalls of each.\n",
    "\n",
    "1. The standard per-point classifier\n",
    "2. Graphcut\n",
    "3. Localised smoothing\n",
    "\n",
    "Please replace the file paths with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = \"/path/to/std.ply\"\n",
    "gcut = \"/path/to/gcut.ply\"\n",
    "lsmth = \"/path/to/localsmooth.ply\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard algorithm\n",
    "\n",
    "Classifying per pixel, with no attempt at post process generalisation.\n",
    "\n",
    "This may be noisier - but it is dependent on the task, classes etc. \n",
    "\n",
    "This will take the least amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(points, labels, classifier, classification)\n",
    "points.write(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localised smoothing\n",
    "\n",
    "Kernelised smoothing....as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_with_local_smoothing(points, labels, classifier,\n",
    "                                      generator.neighborhood().k_neighbor_query(6),\n",
    "                                      classification)\n",
    "\n",
    "points.write(lsmth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphcut\n",
    "\n",
    "Using graphcut to approximate the optimal solution will result in a smoother classification - but may lose clarity. This will require more time to process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_with_graphcut(points, labels, classifier,\n",
    "                               generator.neighborhood().k_neighbor_query(6),\n",
    "                               0.5,  # strength of graphcut\n",
    "                               12,   # nb subdivisions (speed up)\n",
    "                               classification)\n",
    "\n",
    "points.write(gcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "\n",
    "You should end up with a map similar to this using the graphcut method, which for this example is the most effective. This could be improved upon with more training, but the results are largely correct (**the colours will be different in Cloud Compare - I have used the CGAL viewer as the colours are more intuitive and less unpleasant to look at!**).\n",
    "\n",
    "- Yellow = Ground\n",
    "- Green=Trees/Clutter\n",
    "- Red = Roof\n",
    "- Blue = Facade\n",
    "\n",
    "<img src=\"Figures/LlandinamGcut.png\" style=\"height:500px\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the functionality covered herein is in the script below. \n",
    "\n",
    "Where:\n",
    "\n",
    "- i = the input cloud\n",
    "- o = the output cloud\n",
    "- m = the classification regularisation method\n",
    "- f = fix the ply (cloud) file if you have used cloud compare to generate training (not used below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cgalpointclassif.py -i 'Llandinam.ply' -o 'results.ply' -m 'graphcut'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
