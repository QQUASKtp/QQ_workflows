{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object based training and classification using machine learning\n",
    "----------------------\n",
    "\n",
    "### A simple land cover mapping example using aerial photography \n",
    "\n",
    "The following workflow demonstrates using image segmentation and machine learning to produce landcover classes, the priniciples of which broadly apply to much remote sensing work. This was produced as an example to demostrate a landcover map for input to the ALMRS project. Image segmentation is often used to reduce noisy/detailed imagery to lancover classes greater in spatial coverage than the detail within the image. \n",
    "\n",
    "This kind of task is typical of that performed in environmental remote sensing by academic, research and commercial entities to map large areas but will always require QA/correction no matter the complexity of the approach. \n",
    "\n",
    "The data:\n",
    "\n",
    "- Colour infra-red imagery collected over ther Arun Valley, Sussex (G, R, NiR)\n",
    "\n",
    "- shapefiles of the training samples\n",
    "\n",
    "Dependencies :\n",
    "\n",
    "The code below uses geospatial-learn a library developed by Ciaran Robb to apply machine learning libraries to geospatial data. \n",
    "\n",
    "https://github.com/Ciaran1981/geospatial-learn\n",
    "\n",
    "Whilst it is possible to use matplotlib to visualise some results in this notebook, QGIS 3 offers a more versatile platform for this purpose for the final datasets, so please ensure this is installed. Once installed, install the HCMGIS plugin to use various web-based base-layers for visualisation purposes. \n",
    "\n",
    "OTB is used briefly to segment the imagery via the command line:\n",
    "\n",
    "https://anaconda.org/orfeotoolbox/otb\n",
    "\n",
    "**Assumed knowledge:**\n",
    "\n",
    "Basic GIS, image processing, remote sensing, python and command line use\n",
    "\n",
    "Remember to query function args open a new cell (the plus icon) and write the function with a question mark - i.e\n",
    "\n",
    "```python \n",
    "learning?\n",
    "```\n",
    "The lines of code have been written with readability in mind making each step as clear as possible, hence they are obviously not the briefest/most efficient way of doing things!\n",
    "\n",
    "The principal lib used here is geospatial_learn, on which there are further details below. This script will train and classify polygon attributes. This task could be performed with a number of other libs most notable RSGISlib and Orfeo toolbox, on which there is plenty of online material. \n",
    "\n",
    "**Disclaimer! I do not claim this is good model or set of classes!!** \n",
    "\n",
    "**This is merely to demonstrate the funtionality on a segmentation derived from fine spatial resolution data**\n",
    "\n",
    "Obviously, the reality of this type of approach is using large training sets and lengthier model parameter searches are required, as datasets are bigger than this small demonstration. \n",
    "\n",
    "**The Data**\n",
    "\n",
    "The data is temporarily found here until QinetiQ find somewhere to store it and is the LandCover.zip file.\n",
    "\n",
    "https://drive.google.com/open?id=1eM5pwMMwLSzp7S3fr-NJr6pzDi3tD0n3\n",
    "\n",
    "The zip contains:\n",
    "\n",
    "- Arundel_WWT.tif (a Green/Red/NIR composite)\n",
    "- Arundel_train.gz (a compressed scikit-learn training array for the later pixel based training)\n",
    "- ArunLcover.qml (a QGIS colour map for the results)\n",
    "- Arundel_seg_empty.shp (the result of segmentation performed in this analysis complete with training labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module imports\n",
    "----------------------\n",
    "\n",
    "As mentioned above, the code above imports the modules required for this image classification workflow, using the Object-based image analysis method on polygonal data.\n",
    "\n",
    "Here are the links for the underlying libs:\n",
    "- numpy (array processing) \n",
    "    http://www.numpy.org/\n",
    "- matplotlib (plotting and graphics)\n",
    "    https://matplotlib.org/    \n",
    "- gdal (geospatial processing)\n",
    "    http://www.gdal.org/\n",
    "- scikit-learn (one of the main machine learning libs used in geospatial-learn).\n",
    "    https://scikit-learn.org/\n",
    "\n",
    "The final module, geospatial learn for applying machine learning libraries to geospatial data. I also includes some other geospatial functions for raster and vector data. \n",
    "\n",
    "Info on installation can be found here:\n",
    "\n",
    "https://github.com/Ciaran1981/geospatial-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bigdrive/anaconda3/lib/python3.5/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdal\n",
    "from geospatial_learn import learning, shape, raster\n",
    "import shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 'my/path/LandCover'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msRas = ('Arundel_WWT.tif')\n",
    "\n",
    "segShape = ('Arundel_seg_empty.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate stats for segmentation\n",
    "\n",
    "Using an otb generated segmentation....\n",
    "\n",
    "You could alternatively use otb commands, monteverdi or qgis. \n",
    "\n",
    "The otb command for reference\n",
    "\n",
    "```bash\n",
    "otbcli_Segmentation -in path/to/image -filter meanshift -filter.meanshift.spatialr 5 -filter.meanshift.ranger 10 \n",
    "-filter.meanshift.minsize 50 -mode vector -mode.vector.out path/to/outShape\n",
    "```                     \n",
    "\n",
    "We prefix the command line with ! to execute in this notebook as this is external to python\n",
    "\n",
    "**Only run this if you wish to either experiment with parameters and/or wish to label the training segments yourself! Uncomment if this is the case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!otbcli_Segmentation -in path/to/image -filter meanshift -filter.meanshift.spatialr 5 -filter.meanshift.ranger 10 -filter.meanshift.minsize 50 -mode vector -mode.vector.out path/to/outShape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection of statistics\n",
    "----------------------------\n",
    "\n",
    "Segment attribute data is written to the labeled shapefile using the shape.zonal_stats and shape.texture_stats function from geospatial_learn.\n",
    "\n",
    "Rather than repeat the same line of code for each band, a simple for loop is used below to extract the band data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:06<00:00, 939.67it/s]\n",
      "  0%|          | 0/5768 [00:00<?, ?it/s]/bigdrive/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py:639: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 730.65it/s]\n",
      "100%|██████████| 5768/5768 [00:08<00:00, 689.07it/s]\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 737.94it/s]\n",
      "100%|██████████| 5768/5768 [00:06<00:00, 939.61it/s]\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 724.79it/s]\n",
      "100%|██████████| 5768/5768 [00:09<00:00, 635.29it/s]\n",
      "100%|██████████| 5768/5768 [00:08<00:00, 706.75it/s]\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 797.98it/s]\n",
      "100%|██████████| 5768/5768 [00:08<00:00, 703.69it/s]\n",
      "100%|██████████| 5768/5768 [00:09<00:00, 622.35it/s]\n",
      "100%|██████████| 5768/5768 [00:09<00:00, 636.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# zonal stats\n",
    "# please note that by using enumerate we assume the bandnames are ordered as the are in the image!\n",
    "bandnames = ['g', 'r', 'nir']\n",
    "\n",
    "\n",
    "# Please note we add 1 to the bnd index as python counts from zero\n",
    "for bnd,name in enumerate(bandnames):\n",
    "    shape.zonal_stats(segShape, msRas, bnd+1, name+'mn', stat = 'mean', write_stat = True)\n",
    "    shape.zonal_stats(segShape, msRas, bnd+1, name+'mdn', stat = 'median', write_stat = True)\n",
    "    shape.zonal_stats(segShape, msRas, bnd+1, name+'skw', stat = 'skew', write_stat = True)\n",
    "    shape.zonal_stats(segShape, msRas, bnd+1, name+'krt', stat = 'kurtosis', write_stat = True)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:08<00:00, 710.57it/s]\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 788.76it/s]\n",
      "100%|██████████| 5768/5768 [00:07<00:00, 769.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# texture props\n",
    "bandnames = ['g', 'r', 'nir']\n",
    "\n",
    "for bnd,name in enumerate(bandnames):\n",
    "    shape.texture_stats(segShape, msRas,  bnd+1,  gprop='entropy',  write_stat=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/5768 [00:00<00:28, 199.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:08<00:00, 690.03it/s]\n",
      "  2%|▏         | 99/5768 [00:00<00:05, 983.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:06<00:00, 905.26it/s]\n",
      "  3%|▎         | 171/5768 [00:00<00:03, 1700.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:02<00:00, 2176.31it/s]\n",
      "  1%|▏         | 86/5768 [00:00<00:06, 859.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:05<00:00, 995.02it/s] \n",
      "  5%|▍         | 267/5768 [00:00<00:02, 2666.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:02<00:00, 2195.98it/s]\n",
      "  5%|▍         | 270/5768 [00:00<00:02, 2693.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:02<00:00, 2231.83it/s]\n",
      "  0%|          | 0/5768 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:02<00:00, 2206.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# shape props\n",
    "\n",
    "props = ['MajorAxisLength', 'MinorAxisLength', 'Area', 'Eccentricity', 'Solidity',\n",
    "         'Extent', 'Perimeter']\n",
    "for prop in props:\n",
    "    shape.shape_props(segShape, prop, label_field = 'DN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model training\n",
    "\n",
    "Now that we have collected our training statistics, we can calibrate our chosen model, which, in this case is a random forest.\n",
    "\n",
    "Geospatial_learn wraps scikit-learn (hence the name) and xgboost, two excellent machine learning libraries (I intend to add tensor flow to this shortly also!).\n",
    "\n",
    "Typically, we collect training from a shapefile and save it as a .gz file with the get_training_shp function, though it is possible to feed the training array straight into the create_model function.\n",
    "\n",
    "The label and feature fields respectively. \n",
    "\n",
    "```python\n",
    "\n",
    "   label_field = 'Train'\n",
    "\n",
    "   feat_fields = ['gmn','gmdn','gskw','gkrt','rmn','rmdn','rskw','rkrt','nirmn','nirmdn',\n",
    "                  'nirskw','nirkrt','entropy','entropy_1','entropy_2']\n",
    "```\n",
    "\n",
    "Path to the training array we intend to save. This is optional, it is possible to run\n",
    "\n",
    "```python\n",
    "\n",
    "   training = '/savemytraining.gz'\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "   dfTrain, rejects = learning.get_training_shp(segShape, label_field, feat_fields,  outFile = training)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivational lazyness\n",
    "\n",
    "**Here is a quick way of getting a list of the fields to be used as features in the training and classification without typing them out**\n",
    "\n",
    "Here a list comprehension is used with the pyshp (shapefile) lib. This is not really that important, but if you are interested, it is a useful python concept....\n",
    "\n",
    "If you are not familiar with list comprehensions, here is an attempt at explanation in the context of the shapefile. List comprehensions are useful, comapct and readable way of performing an operation on data.\n",
    "\n",
    "The shapefile is read in as a python class object. A class is a fundamental part of object-based programming  (nothing to with the current task!!!) where the data structure has: \n",
    "\n",
    "* properties - effectively attributes of the data\n",
    "\n",
    "* methods - built in operations on the data\n",
    "\n",
    "Below r is the 'object' read in by the pyshp library\n",
    "\n",
    "```python\n",
    "\n",
    "r = shapefile.Reader(segShape)\n",
    "```\n",
    "The shapefile has a 'fields' property, but this returns a list in which each entry has the field name, datatype length, value. So each entry contains superfluous info:\n",
    "```python\n",
    "\n",
    " [\"AREA\", \"N\", 18, 5],\n",
    "\n",
    "```\n",
    "\n",
    "Where as we are only interested in the first part of every entry, which is the field name. \n",
    "\n",
    "so this code is basically saying, output the first part (f[0]) of each entry (f) in the fields property (r.fields)\n",
    "\n",
    "```python\n",
    "[f[0] for f in r.fields]\n",
    "```\n",
    "Hence we end up with a list of only the field titles. Which gives us the names of all the properties.\n",
    "\n",
    "Finally we exclude the DN and Train fields by indexing.\n",
    "\n",
    "```python\n",
    "feat_fields[3:25]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = shapefile.Reader(segShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gmn',\n",
       " 'gmdn',\n",
       " 'gskw',\n",
       " 'gkrt',\n",
       " 'rmn',\n",
       " 'rmdn',\n",
       " 'rskw',\n",
       " 'rkrt',\n",
       " 'nirmn',\n",
       " 'nirmdn',\n",
       " 'nirskw',\n",
       " 'nirkrt',\n",
       " 'entro1',\n",
       " 'entro2',\n",
       " 'entro3',\n",
       " 'MjAxis',\n",
       " 'MnAxis',\n",
       " 'Area',\n",
       " 'Eccen',\n",
       " 'Solid',\n",
       " 'Extent',\n",
       " 'Perim']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_fields = [f[0] for f in r.fields]\n",
    "feat_fields = feat_fields[3:25]\n",
    "feat_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to create some training samples\n",
    "\n",
    "These can be used in both a pixel and object based manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables returned are a dataframe (like in R) and a list of reject polygons which may have had invalid geometry.\n",
    "\n",
    "In practice there shouldn't be many of these - it's just to make sure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 752/5768 [00:00<00:00, 7517.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n",
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:00<00:00, 9059.06it/s]\n"
     ]
    }
   ],
   "source": [
    "training = 'Arundel_train_ob.gz'\n",
    "\n",
    "label_field = 'Train'\n",
    "\n",
    "dfTrain, rejects = learning.get_training_shp(segShape, label_field, feat_fields,  outFile = training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick look at the returned dataframe to see the information. Dataframes are handy to visualise in jupyter and ipython. The create_model accepts the raw array data though so the .as_matrix() property of the dataframe is used when inputting to create_model\n",
    "\n",
    "The first column is the label, the rest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>gmn</th>\n",
       "      <th>gmdn</th>\n",
       "      <th>gskw</th>\n",
       "      <th>gkrt</th>\n",
       "      <th>rmn</th>\n",
       "      <th>rmdn</th>\n",
       "      <th>rskw</th>\n",
       "      <th>rkrt</th>\n",
       "      <th>nirmn</th>\n",
       "      <th>...</th>\n",
       "      <th>entro1</th>\n",
       "      <th>entro2</th>\n",
       "      <th>entro3</th>\n",
       "      <th>MjAxis</th>\n",
       "      <th>MnAxis</th>\n",
       "      <th>Area</th>\n",
       "      <th>Eccen</th>\n",
       "      <th>Solid</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.137405</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.794978</td>\n",
       "      <td>0.345237</td>\n",
       "      <td>32.656489</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.339259</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>49.778626</td>\n",
       "      <td>...</td>\n",
       "      <td>4.066501</td>\n",
       "      <td>4.066501</td>\n",
       "      <td>4.066501</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.673993</td>\n",
       "      <td>0.479853</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>163.718954</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-0.511758</td>\n",
       "      <td>-0.266084</td>\n",
       "      <td>124.248366</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-0.381341</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>138.575163</td>\n",
       "      <td>...</td>\n",
       "      <td>4.010455</td>\n",
       "      <td>4.010455</td>\n",
       "      <td>4.010455</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>38.25</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.714286</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.439138</td>\n",
       "      <td>2.549059</td>\n",
       "      <td>66.028571</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.227215</td>\n",
       "      <td>-0.648337</td>\n",
       "      <td>85.057143</td>\n",
       "      <td>...</td>\n",
       "      <td>3.734799</td>\n",
       "      <td>3.734799</td>\n",
       "      <td>3.734799</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.25</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>142.213675</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-0.801954</td>\n",
       "      <td>0.283542</td>\n",
       "      <td>209.829060</td>\n",
       "      <td>224.0</td>\n",
       "      <td>-0.821063</td>\n",
       "      <td>-0.390233</td>\n",
       "      <td>206.042735</td>\n",
       "      <td>...</td>\n",
       "      <td>3.677674</td>\n",
       "      <td>3.677674</td>\n",
       "      <td>3.677674</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.25</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.803571</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.146892</td>\n",
       "      <td>-1.190404</td>\n",
       "      <td>58.880952</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>-0.931439</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.098618</td>\n",
       "      <td>4.098618</td>\n",
       "      <td>4.098618</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train         gmn   gmdn      gskw      gkrt         rmn   rmdn      rskw  \\\n",
       "0    NaN   23.137405   22.0  0.794978  0.345237   32.656489   33.0 -0.339259   \n",
       "1    NaN  163.718954  165.0 -0.511758 -0.266084  124.248366  125.0 -0.381341   \n",
       "2    NaN   40.714286   37.0  1.439138  2.549059   66.028571   64.0  0.227215   \n",
       "3    NaN  142.213675  149.0 -0.801954  0.283542  209.829060  224.0 -0.821063   \n",
       "4    NaN   76.803571   71.0  0.146892 -1.190404   58.880952   54.5  0.348225   \n",
       "\n",
       "       rkrt       nirmn  ...      entro1    entro2    entro3  MjAxis  MnAxis  \\\n",
       "0  0.014900   49.778626  ...    4.066501  4.066501  4.066501    10.5     6.5   \n",
       "1  0.275526  138.575163  ...    4.010455  4.010455  4.010455     9.0     6.5   \n",
       "2 -0.648337   85.057143  ...    3.734799  3.734799  3.734799     7.5     4.5   \n",
       "3 -0.390233  206.042735  ...    3.677674  3.677674  3.677674     7.0     6.0   \n",
       "4 -0.931439   75.750000  ...    4.098618  4.098618  4.098618     9.5     6.0   \n",
       "\n",
       "    Area     Eccen     Solid    Extent  Perim  \n",
       "0  32.75  0.619048  0.673993  0.479853   35.0  \n",
       "1  38.25  0.722222  0.811966  0.653846   34.0  \n",
       "2  26.25  0.600000  0.888889  0.777778   26.0  \n",
       "3  29.25  0.857143  0.851190  0.696429   30.0  \n",
       "4  42.00  0.631579  0.822368  0.736842   32.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation with k-fold cross validated grid search\n",
    "\n",
    "Now we can train the model with the above data.\n",
    "\n",
    "We first define the parameters we wish to grid search over. The parameters below are just an example, It is of course possible for these to be more numerous at the cost of processing time. The time is a function of the number of possibilities per parameter.\n",
    "\n",
    "```python\n",
    "\n",
    "    params = {'n_estimators': [500], 'max_features': ['sqrt', 'log2'], \n",
    "              'min_samples_split':[5,10,20,50], 'min_samples_leaf': [5,10,20,50]}\n",
    "```          \n",
    "When we execute the create_model function we get a summary of the no of model fits\n",
    "\n",
    "'Fitting 5 folds for each of 18 candidates, totalling 90 fits'\n",
    "\n",
    "I have fixed the n_estimators (trees) at 500 below but this could be varied also.\n",
    "\n",
    "For a full list of params see:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [500], 'max_features': ['sqrt', 'log2'], \n",
    "          'min_samples_split':[5,10,20,50], 'min_samples_leaf': [5,10,20,50]}\n",
    "\n",
    "outModel = 'Arundel_Rf_model2.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_model function is executed below. The progress of the gird search is printed out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, total=   1.6s\n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50, total=   2.1s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50, total=   1.7s\n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50, total=   1.7s\n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=5, min_samples_split=50, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5, total=   2.0s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=10, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=20, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=10, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=20, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=sqrt, min_samples_leaf=50, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5, total=   2.0s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5, total=   2.0s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=10, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=20, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=5, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10, total=   2.0s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20, total=   1.9s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=20, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=10, min_samples_split=50, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20, total=   1.4s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50, total=   1.4s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50, total=   1.8s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=20, min_samples_split=50, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=5, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10, total=   1.4s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10, total=   1.5s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20, total=   1.6s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=10, total=   1.7s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20, total=   1.4s\n",
      "[CV] n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50 \n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20, total=   1.5s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20, total=   1.6s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=20, total=   1.9s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50, total=   1.4s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50, total=   1.5s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50, total=   1.2s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50, total=   1.2s\n",
      "[CV]  n_estimators=500, max_features=log2, min_samples_leaf=50, min_samples_split=50, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   39.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mean_fit_time': array([ 1.50872488,  1.51436744,  1.57326598,  1.55226393,  1.56958461,\n",
       "          1.55623751,  1.56075115,  1.56007099,  1.50644679,  1.47504239,\n",
       "          1.51123147,  1.50157256,  1.55127969,  1.52063823,  1.46122823,\n",
       "          1.5560411 ,  1.59901457,  1.61157541,  1.59551826,  1.58469734,\n",
       "          1.55674429,  1.54279284,  1.49735241,  1.53992038,  1.43175893,\n",
       "          1.46458449,  1.38039598,  1.46210413,  1.4298285 ,  1.38941865,\n",
       "          1.42520275,  1.21176138]),\n",
       "  'mean_score_time': array([ 0.17043281,  0.14491644,  0.20394897,  0.18565578,  0.20009732,\n",
       "          0.19492154,  0.1897604 ,  0.20752158,  0.20721045,  0.1515625 ,\n",
       "          0.20768065,  0.22716985,  0.19857974,  0.21586461,  0.18697395,\n",
       "          0.20345473,  0.22167563,  0.22935781,  0.21588917,  0.22117815,\n",
       "          0.23811502,  0.22967615,  0.16961441,  0.20381079,  0.15167356,\n",
       "          0.21639657,  0.21316767,  0.18847208,  0.17261543,  0.16867814,\n",
       "          0.18749652,  0.10193172]),\n",
       "  'mean_test_score': array([ 0.8452381 ,  0.8452381 ,  0.83333333,  0.80357143,  0.82738095,\n",
       "          0.82738095,  0.82738095,  0.79464286,  0.77083333,  0.77083333,\n",
       "          0.77083333,  0.76785714,  0.55654762,  0.55654762,  0.55654762,\n",
       "          0.55654762,  0.8452381 ,  0.8452381 ,  0.83333333,  0.80357143,\n",
       "          0.82738095,  0.82738095,  0.82738095,  0.79464286,  0.77083333,\n",
       "          0.77083333,  0.77083333,  0.76785714,  0.55654762,  0.55654762,\n",
       "          0.55654762,  0.55654762]),\n",
       "  'mean_train_score': array([ 0.92108126,  0.92108126,  0.88465693,  0.8630673 ,  0.86754493,\n",
       "          0.86754493,  0.86754493,  0.85189532,  0.82514227,  0.82514227,\n",
       "          0.82514227,  0.81770985,  0.60067296,  0.60067296,  0.60067296,\n",
       "          0.60067296,  0.92108126,  0.92108126,  0.88465693,  0.8630673 ,\n",
       "          0.86754493,  0.86754493,  0.86754493,  0.85189532,  0.82514227,\n",
       "          0.82514227,  0.82514227,  0.81770985,  0.60067296,  0.60067296,\n",
       "          0.60067296,  0.60067296]),\n",
       "  'param_max_features': masked_array(data = ['sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt'\n",
       "   'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'sqrt' 'log2' 'log2' 'log2' 'log2'\n",
       "   'log2' 'log2' 'log2' 'log2' 'log2' 'log2' 'log2' 'log2' 'log2' 'log2'\n",
       "   'log2' 'log2'],\n",
       "               mask = [False False False False False False False False False False False False\n",
       "   False False False False False False False False False False False False\n",
       "   False False False False False False False False],\n",
       "         fill_value = ?),\n",
       "  'param_min_samples_leaf': masked_array(data = [5 5 5 5 10 10 10 10 20 20 20 20 50 50 50 50 5 5 5 5 10 10 10 10 20 20 20\n",
       "   20 50 50 50 50],\n",
       "               mask = [False False False False False False False False False False False False\n",
       "   False False False False False False False False False False False False\n",
       "   False False False False False False False False],\n",
       "         fill_value = ?),\n",
       "  'param_min_samples_split': masked_array(data = [5 10 20 50 5 10 20 50 5 10 20 50 5 10 20 50 5 10 20 50 5 10 20 50 5 10 20\n",
       "   50 5 10 20 50],\n",
       "               mask = [False False False False False False False False False False False False\n",
       "   False False False False False False False False False False False False\n",
       "   False False False False False False False False],\n",
       "         fill_value = ?),\n",
       "  'param_n_estimators': masked_array(data = [500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n",
       "   500 500 500 500 500 500 500 500 500 500 500 500 500 500],\n",
       "               mask = [False False False False False False False False False False False False\n",
       "   False False False False False False False False False False False False\n",
       "   False False False False False False False False],\n",
       "         fill_value = ?),\n",
       "  'params': [{'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'sqrt',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 5,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 10,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 20,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 5,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 10,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 20,\n",
       "    'n_estimators': 500},\n",
       "   {'max_features': 'log2',\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 50,\n",
       "    'n_estimators': 500}],\n",
       "  'rank_test_score': array([ 1,  1,  5, 13,  7,  7,  7, 15, 17, 17, 17, 23, 25, 25, 25, 25,  1,\n",
       "          1,  5, 13,  7,  7,  7, 15, 17, 17, 17, 23, 25, 25, 25, 25], dtype=int32),\n",
       "  'split0_test_score': array([ 0.8115942 ,  0.8115942 ,  0.8115942 ,  0.7826087 ,  0.8115942 ,\n",
       "          0.8115942 ,  0.8115942 ,  0.79710145,  0.76811594,  0.76811594,\n",
       "          0.76811594,  0.76811594,  0.49275362,  0.49275362,  0.49275362,\n",
       "          0.49275362,  0.8115942 ,  0.8115942 ,  0.8115942 ,  0.7826087 ,\n",
       "          0.8115942 ,  0.8115942 ,  0.8115942 ,  0.79710145,  0.76811594,\n",
       "          0.76811594,  0.76811594,  0.76811594,  0.49275362,  0.49275362,\n",
       "          0.49275362,  0.49275362]),\n",
       "  'split0_train_score': array([ 0.89513109,  0.89513109,  0.88014981,  0.86891386,  0.87265918,\n",
       "          0.87265918,  0.87265918,  0.86516854,  0.86142322,  0.86142322,\n",
       "          0.86142322,  0.86142322,  0.6329588 ,  0.6329588 ,  0.6329588 ,\n",
       "          0.6329588 ,  0.89513109,  0.89513109,  0.88014981,  0.86891386,\n",
       "          0.87265918,  0.87265918,  0.87265918,  0.86516854,  0.86142322,\n",
       "          0.86142322,  0.86142322,  0.86142322,  0.6329588 ,  0.6329588 ,\n",
       "          0.6329588 ,  0.6329588 ]),\n",
       "  'split1_test_score': array([ 0.85294118,  0.85294118,  0.82352941,  0.79411765,  0.79411765,\n",
       "          0.79411765,  0.79411765,  0.76470588,  0.73529412,  0.73529412,\n",
       "          0.73529412,  0.72058824,  0.60294118,  0.60294118,  0.60294118,\n",
       "          0.60294118,  0.85294118,  0.85294118,  0.82352941,  0.79411765,\n",
       "          0.79411765,  0.79411765,  0.79411765,  0.76470588,  0.73529412,\n",
       "          0.73529412,  0.73529412,  0.72058824,  0.60294118,  0.60294118,\n",
       "          0.60294118,  0.60294118]),\n",
       "  'split1_train_score': array([ 0.9141791 ,  0.9141791 ,  0.87686567,  0.84701493,  0.85447761,\n",
       "          0.85447761,  0.85447761,  0.8358209 ,  0.79104478,  0.79104478,\n",
       "          0.79104478,  0.77985075,  0.63059701,  0.63059701,  0.63059701,\n",
       "          0.63059701,  0.9141791 ,  0.9141791 ,  0.87686567,  0.84701493,\n",
       "          0.85447761,  0.85447761,  0.85447761,  0.8358209 ,  0.79104478,\n",
       "          0.79104478,  0.79104478,  0.77985075,  0.63059701,  0.63059701,\n",
       "          0.63059701,  0.63059701]),\n",
       "  'split2_test_score': array([ 0.82352941,  0.82352941,  0.82352941,  0.77941176,  0.80882353,\n",
       "          0.80882353,  0.80882353,  0.75      ,  0.75      ,  0.75      ,\n",
       "          0.75      ,  0.75      ,  0.57352941,  0.57352941,  0.57352941,\n",
       "          0.57352941,  0.82352941,  0.82352941,  0.82352941,  0.77941176,\n",
       "          0.80882353,  0.80882353,  0.80882353,  0.75      ,  0.75      ,\n",
       "          0.75      ,  0.75      ,  0.75      ,  0.57352941,  0.57352941,\n",
       "          0.57352941,  0.57352941]),\n",
       "  'split2_train_score': array([ 0.94029851,  0.94029851,  0.89552239,  0.86567164,  0.87313433,\n",
       "          0.87313433,  0.87313433,  0.84701493,  0.81716418,  0.81716418,\n",
       "          0.81716418,  0.80970149,  0.5858209 ,  0.5858209 ,  0.5858209 ,\n",
       "          0.5858209 ,  0.94029851,  0.94029851,  0.89552239,  0.86567164,\n",
       "          0.87313433,  0.87313433,  0.87313433,  0.84701493,  0.81716418,\n",
       "          0.81716418,  0.81716418,  0.80970149,  0.5858209 ,  0.5858209 ,\n",
       "          0.5858209 ,  0.5858209 ]),\n",
       "  'split3_test_score': array([ 0.89552239,  0.89552239,  0.86567164,  0.80597015,  0.88059701,\n",
       "          0.88059701,  0.88059701,  0.80597015,  0.79104478,  0.79104478,\n",
       "          0.79104478,  0.79104478,  0.58208955,  0.58208955,  0.58208955,\n",
       "          0.58208955,  0.89552239,  0.89552239,  0.86567164,  0.80597015,\n",
       "          0.88059701,  0.88059701,  0.88059701,  0.80597015,  0.79104478,\n",
       "          0.79104478,  0.79104478,  0.79104478,  0.58208955,  0.58208955,\n",
       "          0.58208955,  0.58208955]),\n",
       "  'split3_train_score': array([ 0.92565056,  0.92565056,  0.88104089,  0.85873606,  0.86245353,\n",
       "          0.86245353,  0.86245353,  0.8401487 ,  0.81784387,  0.81784387,\n",
       "          0.81784387,  0.80669145,  0.62825279,  0.62825279,  0.62825279,\n",
       "          0.62825279,  0.92565056,  0.92565056,  0.88104089,  0.85873606,\n",
       "          0.86245353,  0.86245353,  0.86245353,  0.8401487 ,  0.81784387,\n",
       "          0.81784387,  0.81784387,  0.80669145,  0.62825279,  0.62825279,\n",
       "          0.62825279,  0.62825279]),\n",
       "  'split4_test_score': array([ 0.84375 ,  0.84375 ,  0.84375 ,  0.859375,  0.84375 ,  0.84375 ,\n",
       "          0.84375 ,  0.859375,  0.8125  ,  0.8125  ,  0.8125  ,  0.8125  ,\n",
       "          0.53125 ,  0.53125 ,  0.53125 ,  0.53125 ,  0.84375 ,  0.84375 ,\n",
       "          0.84375 ,  0.859375,  0.84375 ,  0.84375 ,  0.84375 ,  0.859375,\n",
       "          0.8125  ,  0.8125  ,  0.8125  ,  0.8125  ,  0.53125 ,  0.53125 ,\n",
       "          0.53125 ,  0.53125 ]),\n",
       "  'split4_train_score': array([ 0.93014706,  0.93014706,  0.88970588,  0.875     ,  0.875     ,\n",
       "          0.875     ,  0.875     ,  0.87132353,  0.83823529,  0.83823529,\n",
       "          0.83823529,  0.83088235,  0.52573529,  0.52573529,  0.52573529,\n",
       "          0.52573529,  0.93014706,  0.93014706,  0.88970588,  0.875     ,\n",
       "          0.875     ,  0.875     ,  0.875     ,  0.87132353,  0.83823529,\n",
       "          0.83823529,  0.83823529,  0.83088235,  0.52573529,  0.52573529,\n",
       "          0.52573529,  0.52573529]),\n",
       "  'std_fit_time': array([ 0.02217869,  0.04212304,  0.04093826,  0.171433  ,  0.12848837,\n",
       "          0.06393942,  0.09364063,  0.06270909,  0.03582526,  0.11197465,\n",
       "          0.06724278,  0.12612004,  0.085065  ,  0.08092455,  0.07535167,\n",
       "          0.04395134,  0.12259332,  0.05834313,  0.0725759 ,  0.0819313 ,\n",
       "          0.07920628,  0.11278129,  0.16220687,  0.06357211,  0.12485807,\n",
       "          0.05851761,  0.10924134,  0.09140069,  0.05370618,  0.0784718 ,\n",
       "          0.14756711,  0.14284402]),\n",
       "  'std_score_time': array([ 0.0426931 ,  0.05181888,  0.00119678,  0.04039584,  0.05017442,\n",
       "          0.04916689,  0.0440981 ,  0.00282775,  0.00403252,  0.04854391,\n",
       "          0.00631235,  0.01645792,  0.04922097,  0.01273938,  0.04236053,\n",
       "          0.05147535,  0.02539875,  0.01786957,  0.01528011,  0.01754322,\n",
       "          0.01467858,  0.01879451,  0.04252078,  0.0513333 ,  0.04553326,\n",
       "          0.00761507,  0.01162374,  0.04362128,  0.05538812,  0.05399255,\n",
       "          0.04192551,  0.00035387]),\n",
       "  'std_test_score': array([ 0.02905941,  0.02905941,  0.01910897,  0.02864881,  0.03099258,\n",
       "          0.03099258,  0.03099258,  0.03754584,  0.02751572,  0.02751572,\n",
       "          0.02751572,  0.03167914,  0.03977041,  0.03977041,  0.03977041,\n",
       "          0.03977041,  0.02905941,  0.02905941,  0.01910897,  0.02864881,\n",
       "          0.03099258,  0.03099258,  0.03099258,  0.03754584,  0.02751572,\n",
       "          0.02751572,  0.02751572,  0.03167914,  0.03977041,  0.03977041,\n",
       "          0.03977041,  0.03977041]),\n",
       "  'std_train_score': array([ 0.01544941,  0.01544941,  0.00689411,  0.0095895 ,  0.00786959,\n",
       "          0.00786959,  0.00786959,  0.0139558 ,  0.02352569,  0.02352569,\n",
       "          0.02352569,  0.02721479,  0.04131515,  0.04131515,  0.04131515,\n",
       "          0.04131515,  0.01544941,  0.01544941,  0.00689411,  0.0095895 ,\n",
       "          0.00786959,  0.00786959,  0.00786959,  0.0139558 ,  0.02352569,\n",
       "          0.02352569,  0.02352569,  0.02721479,  0.04131515,  0.04131515,\n",
       "          0.04131515,  0.04131515])},\n",
       " 0.84523809523809523,\n",
       " {'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 5,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 500},\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=5, min_samples_split=5,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "             oob_score=False, random_state=123, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.create_model(dfTrain.as_matrix(), outModel, clf='rf', cv=5, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### So what's happening 'under the hood' in the create_model function?\n",
    "\n",
    "**If you're not bothered about this, skip to the next line of code!!!**\n",
    "\n",
    "geospatial_learn transforms the data into the correct shape and performs the k-fold cross validation grid search in scikit-learn. **The following snippets of code show the fundamental parts. If you are intersested have a look at the file on github, and scroll to the second function 'create_model'** \n",
    "\n",
    "https://github.com/Ciaran1981/geospatial-learn/blob/master/geospatial_learn/learning.py\n",
    "\n",
    "Firstly the scikit-learn classifier object is instantiated\n",
    "\n",
    "```python\n",
    "   RF_clf = RandomForestClassifier(n_jobs=-1, random_state = 123)\n",
    "```\n",
    "Here n_jobs is the number of processing core to be allocated to the classifier, Default is -1 which means all available. \n",
    "\n",
    "Random state basically means the Random forest is repeatable without slight changes in results (important as by definition it is random!)\n",
    "\n",
    "\n",
    "The bands variable here is the no of features, y_train is the class labels. Non finite values are removed. You may recognise some of the variable names here from the inputs of the create model function. The GridSearchCV function instatiates the grid search object, then the fit 'method' executes the search. \n",
    "\n",
    "```python\n",
    "\n",
    "    bands = X_train.shape[1]-1\n",
    " \n",
    "    \n",
    "    X_train = X_train[X_train[:,0] != 0]\n",
    "     \n",
    "    # Remove non-finite values\n",
    "    X_train = X_train[np.isfinite(X_train).all(axis=1)]\n",
    "   \n",
    "   # y labels\n",
    "    y_train = X_train[:,0]\n",
    "\n",
    "    # remove labels from X_train\n",
    "    X_train = X_train[:,1:bands+1]\n",
    "\n",
    "    grid = GridSearchCV(RF_clf, param_grid=param_grid, \n",
    "                                cv=StratifiedKFold(cv), n_jobs=cores,\n",
    "                                scoring=scoring, verbose=2)\n",
    "    grid.fit(X_train, y_train)\n",
    "     \n",
    "```\n",
    "\n",
    "The grid search is performed....\n",
    "\n",
    "\n",
    "Then later on the model once the search is finished, the best model parameter combination is saved as a .gz file so it can be used again. the uses the '.best_estimator' property of the grid object. The library joblib is used to compress and save the model.\n",
    "\n",
    "```python\n",
    "\n",
    "    joblib.dump(grid.best_estimator_, outModel) \n",
    "```\n",
    "\n",
    "Hence the create model function has been created to save writing this and lots of other stuff every time!\n",
    "\n",
    "Anyway! back to the task in hand....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is worth checking the shapefile to see everything is written correctly in qgis....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification \n",
    "\n",
    "Having collected training and created a model, we can finally classify our polygon attributes.\n",
    "\n",
    "This is done using the classify object function where:\n",
    "\n",
    "```python\n",
    "\n",
    "   learning.classify_object(outModel, inShape, feat_fields, field_name='RF')\n",
    "   \n",
    "```\n",
    "\n",
    "We reuse the outModel, inShape and feat_fields variables from earlier which leaves only the keyword arg field_name, which is what we intend to call the field holding the classification values.\n",
    "\n",
    "Keep this short if writing to ESRI shapefiles as there is a strict limit to the no of characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping data\n",
      "data ready\n",
      "Classifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:00<00:00, 8647.56it/s]\n"
     ]
    }
   ],
   "source": [
    "learning.classify_object(outModel, segShape, feat_fields, field_name='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model evaluation\n",
    "\n",
    "Have a look at the results in QGIS by using the style file provided\n",
    "\n",
    "Having classified the segmentation - it looks fairly convincing, though some things appear strange, such as slivers of area in the fields classified as trees - could be explored with feature importance. The classifier may be splitting nodes on the basis of a geometric feature which is not actually indicative of trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEKCAYAAADAVygjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbaf313128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning.plot_feature_importances(outModel, feat_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as though kurtosis is not contributing much to the results, neither many spatial properties. MjAxis is however, and may be the reason for the spurious tree mapping. Removing it **could** eliminate this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for a pixel based classification using the same training polygons\n",
    "\n",
    "Bear in mind that the grid search will be much slower as there will be a big rise in the no of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & prepping data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5768 [00:00<10:11,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5768/5768 [00:06<00:00, 935.57it/s] \n"
     ]
    }
   ],
   "source": [
    "tPix = 'Arundel_train.gz'\n",
    "msRas = 'Arundel_WWT.tif'\n",
    "\n",
    "trainPix, rejPix = learning.get_training(segShape, msRas, 3, 'Train', outFile = tPix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To use the existing parameters above**\n",
    "\n",
    "```python\n",
    "outPixmodel = '/media/ciaran/HD-PZFU3/PyScripts/CLCR_tutorials/Arundel_RF_pix.gz'\n",
    "learning.create_model(trainPix, outPixmodel, clf='rf', cv=3, params=params)\n",
    "```\n",
    "This will, however take an absolute age to process on a laptop (96 model fits)\n",
    "\n",
    "When using a huge training set 100k + samples, best to use a powerful machine (lots of cores and RAM or HPC.\n",
    "\n",
    "Also worth bearing in mind that there usually a trade off with different ML algorithms.\n",
    "\n",
    "Simpler models like logistic regression/maxent, CART, naive bayes will be quick to process on large datasetes but more limited in their scope.\n",
    "\n",
    "More complex ensemble models such as RF, GB or non-linears like SVM kernels or various neural nets will take longer to compute.\n",
    "\n",
    "For the sake of brevity here, we will use a very limited parameter set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [500], 'min_samples_split':[5,10], 'min_samples_leaf': [5,10]}\n",
    "\n",
    "outPixmodel = 'arundelPixModel.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=5 .......\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=5 .......\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=5 .......\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=10 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=10 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=5, min_samples_split=10 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=5 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=5 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=5 ......\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=10 .....\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=10 .....\n",
      "[CV] n_estimators=500, min_samples_leaf=10, min_samples_split=10 .....\n"
     ]
    }
   ],
   "source": [
    "learning.create_model(trainPix, outPixmodel, clf='rf', cv=3, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
