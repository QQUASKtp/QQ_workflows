{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Cloud Classification for quick land cover mapping\n",
    "----------------------\n",
    "\n",
    "The following workflow demonstrates point cloud classification using the Computational Geometry Algorithms Library This assumes basic knowledge of python and GIS usage. Compared to the other point cloud algorithms, this method is a little more sophisticated and could be applied to get a quick (i.e. minutes > hour generating training)  characterisation of an environment with relatively little training collection. \n",
    "\n",
    "The paper associated is found here:\n",
    "\n",
    "https://hal.inria.fr/file/index/docid/759265/filename/ijcv_2012.pdf\n",
    "\n",
    "The functions etc. of this workflow can be found here:\n",
    "\n",
    "https://doc.cgal.org/latest/Classification/index.html\n",
    "\n",
    "The algorithm is based on the computation of a set of pointwise geometric attributes (such as planarity, local elevation, etc.). Each type (heath, shrubs, trees) is defined as a linear combination of these attributes. Classification is achieved by minimizing an energy over the input point cloud by selecting, for each point, the classification type that gives the best score. Global regularization is performed by using a graph-cut algorithm (alpha expansion).\n",
    "\n",
    "This dataset is a point cloud of the Cors Fochno SSSI building derived via SfM. The colours will look unusual as they represent the Red, Red-Edge & Near-Infra-Red bands repspectively, which are more informative for distinguising vegetation types. You will get used to it! \n",
    "\n",
    "Dependencies:\n",
    "\n",
    "The code depends on the CGAL library, which can be installed most easily via anaconda or compiled from source.\n",
    "\n",
    "Assumed knowledge:\n",
    "\n",
    "Basic GIS, image processing, remote sensing, python and command line use\n",
    "\n",
    "Remember to query function args open a new cell (the plus icon) and write the function with a question mark - i.e\n",
    "\n",
    "function?\n",
    "\n",
    "As the python CGAL API is a swig binding, docstring on functions may not be very informative. This workflow can also of course be easily executed directly using the C++ api.  \n",
    "\n",
    "The lines of code have been written with readability in mind making each step as clear as possible, hence they are obviously not the briefest/most efficient way of doing things!\n",
    "\n",
    "Data\n",
    "\n",
    "The data is temporarily found in this google drive folder until QinetiQ find somewhere to store it.\n",
    "\n",
    "https://drive.google.com/open?id=1eM5pwMMwLSzp7S3fr-NJr6pzDi3tD0n3\n",
    "\n",
    "The file required is Points.zip - extract this somewhere appropriate and change dir to this folder.\n",
    "\n",
    "This contains:\n",
    "\n",
    "- CorsFochno.ply\n",
    "- ArunLidar.ply\n",
    "\n",
    "**These files are big! You will need a machine with plenty of cores and RAM to process as per this workflow.** \n",
    "\n",
    "The reason for using these datasets is to demostrate the potential of this method over large areas. These datasets could be reduced in size by a combination of cleaning and down-sampling, which could be done with a variety of libraries, including CGAL. Cloud Compare offers the most readily \"accessible\" (i.e. pointing and clicking buttons) to do this.  \n",
    "\n",
    "The training labels are pre-made in the integer field \"label\". If you wish to create your own, the labels must be contiguous signed integers where -1 is nodata, 0,1,2,3 are the classes. This can be done in Cloud Compare (CC) by segmenting the point cloud and labeling with a scalar field. Better still, the whole operation can be run from the CGAL Polyhedron_3 demo GUI, if you follow the compilation instructions for this.\n",
    "\n",
    "The CorsFochno.ply will look like this in CC.\n",
    "\n",
    "<img src=\"Figures/CF.jpg\" style=\"height:500px\">\n",
    "\n",
    "The ArunLidar.ply should look like this by selecting the Classification field to display, where blue is ground and green non-ground.\n",
    "\n",
    "<img src=\"Figures/ArnL.jpg\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module imports \n",
    "----------------------\n",
    "The cgal lib can be found here with several ways to install. \n",
    "\n",
    "https://www.cgal.org/\n",
    "\n",
    "The easiest is the official cgal repositories or anaconda. \n",
    "Install plyfile via pip in the same conda environment.  \n",
    "\n",
    "https://www.cgal.org/download.html\n",
    "\n",
    "https://anaconda.org/conda-forge/cgal\n",
    "\n",
    "However this will not include the demos etc. See the repo README for some info on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CGAL.CGAL_Kernel import Point_3\n",
    "from CGAL.CGAL_Kernel import Vector_3\n",
    "from CGAL.CGAL_Point_set_3 import Point_set_3\n",
    "from CGAL.CGAL_Classification import *\n",
    "from plyfile import PlyData\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and return the no of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45630926 points read\n"
     ]
    }
   ],
   "source": [
    "incloud = '/home/ciaran/BorthPoints/CorsFochno.ply'\n",
    "points = Point_set_3(incloud)\n",
    "print(points.size(), \"points read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels\n",
    "\n",
    "This will enable us to extract the classes in the correct order for CGAL, though they could be predefined. This uses the ply header and pulls out the relevant text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PlyData.read(incloud)\n",
    "clList = pf.comments\n",
    "\n",
    "# apologies for this ugly code!!!\n",
    "if clList[0] == \"Generated by the CGAL library\":\n",
    "    clss = clList[2:len(clList)]\n",
    "    classes = [c.split()[2] for c in clss]\n",
    "    classes.pop(0)\n",
    "    del clss, clList\n",
    "\n",
    "labels = Label_set()\n",
    "for c in classes:\n",
    "    labels.add(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to set different names here is how it is done. Uncomment this and set how you'd prefer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = Label_set()\n",
    "\n",
    "\n",
    "#imperv = labels.add(\"Impervious\") # 0\n",
    "\n",
    "#trees = labels.add(\"Trees\") # 1\n",
    "\n",
    "#shrub = labels.add(\"Shrub\") # 2\n",
    "\n",
    "#water = labels.add(\"Water\") # 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation\n",
    "\n",
    "The following lines generate point features based on the existing fields of the point cloud, eigen values and spatial filters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Feature_set()\n",
    "generator = Point_set_feature_generator(points, 5)\n",
    "\n",
    "features.begin_parallel_additions()\n",
    "generator.generate_point_based_features(features)\n",
    "\n",
    "if points.has_normal_map():\n",
    "    generator.generate_normal_based_features(features, points.normal_map())\n",
    "\n",
    "\n",
    "if points.has_int_map(\"red\") and points.has_int_map(\"green\") and points.has_int_map(\"blue\"):\n",
    "    generator.generate_color_based_features(features,\n",
    "                                            points.int_map(\"red\"),\n",
    "                                            points.int_map(\"green\"),\n",
    "                                            points.int_map(\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the example labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = points.int_map(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we train the classifier and save the model for further use if required (and effective enough!). \n",
    "\n",
    "If you wish to label the training yourself - you will need either Cloud Compare or the CGAL Polyhedron_3 demo.\n",
    "\n",
    "Cloud Compare will facillitate this by segment by a bit of a hacky workaround where you will have to segment bits of the cloud for each class, give them a constant scalar field (the class name) then merge them back together. This is not ideal but works! Here is a link to the tool basics.\n",
    "\n",
    "https://www.cloudcompare.org/doc/wiki/index.php?title=Interactive_Segmentation_Tool\n",
    "\n",
    "Better still, the CGAL_Polyhedron demo can be compliled from the main library but it may become a character building experience doing so. If successful you will have a QT-based GUI to label the data. Otherwise, there a few point labelling applications out there FOSS or proprietary but may not output the correct datatypes for CGAL!\n",
    "\n",
    "Anyway.....\n",
    "\n",
    "First we must create an path for the model to be saved - please insert your own. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outmodel = \"/home/ciaran/BorthPoints/testrf.gz\"\n",
    "#outmodel = \"/path/to/my/model.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = points.add_int_map(\"training\")\n",
    "for idx in points.indices():\n",
    "    training.set(idx, classification.get(idx))\n",
    "\n",
    "print(\"Training random forest classifier...\")\n",
    "classifier = ETHZ_Random_forest_classifier(labels, features)\n",
    "classifier.train(points.range(training), num_trees=50, max_depth=30)\n",
    "\n",
    "print(\"Saving classifier's trained configuration...\")\n",
    "classifier.save_configuration(outmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and output\n",
    "\n",
    "Here we classify via a few different methods to see the merits/pitfalls of each.\n",
    "\n",
    "1. The standard per-point classifier\n",
    "2. Graphcut\n",
    "3. Localised smoothing\n",
    "\n",
    "Please replace the file paths with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = \"/path/to/std.ply\"\n",
    "gcut = \"/path/to/gcut.ply\"\n",
    "lsmth = \"/path/to/localsmooth.ply\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard algorithm\n",
    "\n",
    "Classifying per pixel, with no attempt at post process generalisation.\n",
    "\n",
    "This may be noisier - but it is dependent on the task, classes etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(points, labels, classifier, classification)\n",
    "points.write(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphcut\n",
    "\n",
    "Using graphcut to approximate the optimal solution will result in a smoother classification - but may lose clarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_with_graphcut(points, labels, classifier,\n",
    "                               generator.neighborhood().k_neighbor_query(6),\n",
    "                               0.5,  # strength of graphcut\n",
    "                               12,   # nb subdivisions (speed up)\n",
    "                               classification)\n",
    "\n",
    "points.write(gcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localised smoothing\n",
    "\n",
    "Kernelised smoothing....as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_with_local_smoothing(points, labels, classifier,\n",
    "                                      generator.neighborhood().k_neighbor_query(6),\n",
    "                                      classification)\n",
    "\n",
    "points.write(lsmth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "A potential application of these results is to get a relatively quick look at cover types to inform navigation via a least cost path method (there are plenty of examples of this out there). \n",
    "\n",
    "You should end up with a map similar to this (**the colours will be different in Cloud Compare - I have used the CGAL viewer as the colours are more intuitive**).\n",
    "\n",
    "<img src=\"Figures/BorthPointClass.png\" style=\"height:500px\">\n",
    "\n",
    "\n",
    "Using Cloud Compare, open the point clouds by draging them in the main window and **set the scalar field to label and choose one of the lurid CC colour maps.**\n",
    "\n",
    "<img src=\"Figures/CFCCRes.jpg\" style=\"height:500px\">\n",
    "\n",
    "SfM-based clouds are ultimately limited by the modelled approach, hence we can only attribute and map objects extruded from a surface when surveying with a UAV.\n",
    "\n",
    "### LiDAR\n",
    "\n",
    "LiDAR is a more complete, physically measured system in which we have variable depth information not exploitable with SfM. It is this we turn to next with a DEFRA point cloud of Arundel in Sussex. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than run all of the above again - the script below contains all this functionality - simply run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cgalpointclassif.py -i '/path/to/ArunLidar.ply' -o '/path/to/ArunLidarout.ply'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LiDAR results\n",
    "\n",
    "\n",
    "Given the advantages of knowing the Ground/Non-Ground in advance using LiDAR should in theory offer more promisng results. Though it must be borne in mind that facets of structures are relatively poorly represented as the acquisition is aerial, so lower bulidings walls etc. will have poor point density. \n",
    "\n",
    "Here the classes are High-Veg (dark green), Low veg/clutter (light green), buildings (orange) and ground (grey). \n",
    "\n",
    "You should end up with a map similar to this (**the colours will be different in Cloud Compare - I have used the CGAL viewer as the colours are more intuitive**).\n",
    "\n",
    "<img src=\"Figures/ArnLRs.png\" style=\"height:500px\">\n",
    "\n",
    "This is a crude example with lots of room for improvement! With LiDAR it is possible to produce a very detailed map and utilise properties (e.g. gaps beneath objects - effective floating) to map classes not really possible with SfM (a modelled approach) such as power lines. \n",
    "\n",
    "### Other considerations\n",
    "\n",
    "Using the primitives extracted from a similar map, we could reconstruct the buildings etc. as a mesh surface using similar approaches to that of https://hal.inria.fr/file/index/docid/759265/filename/ijcv_2012.pdf. There are plenty other studies similar to this that are more recent, but follow a largely similar process. \n",
    "\n",
    "Of interest perhaps is the ETH Zurich benchmark dataset for point clouds, from which various machine learning algorithms could be tested.\n",
    "\n",
    "http://semantic3d.net/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
