{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talybont farm Structure from Motion (SfM) workflow\n",
    "----------------------\n",
    "\n",
    "The following workflow demonstrates the full SfM process on a recently collected over a farm site near Talybont-on-Usk, Brecon. The flight was focussed on a sugar beet field from which to eventually derive species diversity information. The remit was to process surface reflectence imagery, ortho-rectify then mosaic  \n",
    "\n",
    "This dataset consists of ~320 image captures ( X 5 including the 5 bands) using the Micasense Red Edge sensor aboard the Bramor PPX fixed wing platform.  \n",
    "\n",
    "The following will run the SfM workflow though some issues made this more difficult, but those have been skipped in this demo and the data is the best pass by the UAV and photos are ready aligned for use.\n",
    "\n",
    "The issues:\n",
    "\n",
    "- Onbard GPS recording failure, hence a reliance on the camera GPS\n",
    "\n",
    "- Three separate passes of the UAV as cloud cover changed\n",
    "\n",
    "- Poor band alignment across all bands\n",
    "\n",
    "Dependencies :\n",
    "\n",
    "Micmac and the SfM scripts as avalaible on the QQ github. \n",
    "\n",
    "You will need to install this python module to run bash commands without constant exclamation marks\n",
    "\n",
    "```bash\n",
    "pip install bash_kernel\n",
    "\n",
    "python -m bash_kernel.install\n",
    "```\n",
    "\n",
    "Whilst it is possible to use matplotlib to visualise some results in this notebook, QGIS 3 offers a more versatile platform for this purpose for the final datasets, so please ensure this is installed. Once installed, install the HCMGIS plugin to use various web-based base-layers for visualisation purposes. \n",
    "\n",
    "https://www.osgeo.org/projects/qgis/\n",
    "\n",
    "Cloud compare or meshlab provide a useful tool to visualise point cloud results and can be found through the links below.\n",
    "\n",
    "https://www.danielgm.net/cc/\n",
    "\n",
    "http://www.meshlab.net/\n",
    "\n",
    "Some extra info at the end of this workflow uses rsgislib, developed at Aberystwyth University (Bunting & Clewley, 2019) to finely register imagery using pixel and geospatial information.  \n",
    "\n",
    "https://www.rsgislib.org/\n",
    "\n",
    "\n",
    "The data:\n",
    "\n",
    "- 2 folders of multispectral imagery RGB & RReNIR\n",
    "- gps log (log.csv)\n",
    "\n",
    "If you wish to skip through it all and just process, use this script, the inards of which are covered here. \n",
    "\n",
    "```bash\n",
    "\n",
    "mspec_sfm.sh -e tif -a Forest -m PIMs -u '30 +north' -c Fraser log.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Alignment\n",
    "\n",
    "The image bands were aligned and outputted using the Micasense python lib. I have saved you the pain of finding a decent image for this which was one of the most problemtaic aspects of this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SfM processng\n",
    "\n",
    "Assuming you have already ```cd'd``` into the workspace containing RGB and RReNir. \n",
    "\n",
    "First we move the RGB data on which most processing is done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv RGB/*.tif $PWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation\n",
    "\n",
    "As with previous notebooks, we process the photo poses and produce a sparse cloud by first processing a relative orientation then the bundle adjustment of GPS etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orientation.sh -e JPG -u \"30 +north\" -c Fraser \"30 +north\" -t \"log.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the images are orientated first in a relative coordinate system, then adjusted with the GPS data (Bundle adjustment). \n",
    "\n",
    "As the main onboard GPS failed to record, we only have the camera GPS data, which at best is accurate to within 3m. Hence we must specify an estimate of this to the function (```gpsAcc```) to enable the relative orientation and GPS position to be weighted appropriately. \n",
    "\n",
    "Had the main GPS worked, we could have specified 1m or less. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of sparse cloud\n",
    "\n",
    "We can look at the sparse point clouds for each dataset to check the result of the orientation in meshlab or cloud compare. This will be a .ply file Aperi_Ground_UTM.ply. \n",
    "\n",
    "As the data is in 16-bit colour depth, the RGB values will not display, hence the points will be white. You will still be able to see the structure is good nonetheless.\n",
    "\n",
    "\n",
    "### Dense matching and output data\n",
    "\n",
    "We will now use the ```PIMs``` function to generate DSM and individual ortho results. \n",
    "\n",
    "This will take some time to run for both datasets!\n",
    "\n",
    "The results will be written to folders named 'OUTPUT'.\n",
    "\n",
    "These may be opened in QGIS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_cloud.sh -e tif -a PIMs -m Forest -i 1 -o 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move the RGB data out and get the Nir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *.tif RGB\n",
    "\n",
    "mv OUTPUT/OrthoImage_geotif.tif OUTPUT/RGB.tif\n",
    "rm -rf OUTPUT/OrthoImage_geotif.tif\n",
    "\n",
    "mv RRENir/*.tif $PWD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the RReNir.... where ```-x 0``` indicates the DSM is not reprocessed, merely the ortho-imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_cloud.sh -e tif -a PIMs -m Forest -o 1 -x 0\n",
    "\n",
    "mv *.tif RRENir\n",
    "\n",
    "mv OUTPUT/OrthoImage_geotif.tif OUTPUT/RReNir.tif\n",
    "rm -rf OUTPUT/OrthoImage_geotif.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaicing was processed using the ```tawny``` function from MicMac. This uses radiometric equalisation by default and should produce satisfactory results and an evenly illuminated mosaic. \n",
    "\n",
    "Check the OUTPUT folder for mosaics and open in QGIS\n",
    "\n",
    "This complete workflow can be achieved by one shell script cmd.\n",
    "\n",
    "```bash\n",
    "\n",
    "mspec_sfm.sh -e tif -a Forest -m PIMs -u '30 +north' -q 1 -d 1 -c Fraser log.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An aside - earlier versions of this workflow resulted in poor registration on RGB & the other bands. Since then an additional function in MicMac has arisen to get around this issue but I have retained this a it is useful. If images to not perfectly register, this handy function in RSGIS has proved useful on numerous occasions. \n",
    "\n",
    "https://www.rsgislib.org/rsgislib_imageregistration.html\n",
    "\n",
    "...and below for the paper.\n",
    "\n",
    "Bunting, P.J., Labrosse, F. & Lucas, R.M., 2010. A multi-resolution area-based technique for automatic multi-modal image registration. Image and Vision Computing, 28(8), pp.1203-1219.\n",
    "\n",
    "It is likely good practice to do this prior to stacking the 3-band mosaics in most cases. \n",
    "\n",
    "The RReNir image will be registered to the RGB image.\n",
    "\n",
    "**Before doing this switch kernels (kernels -> Change kernels) on the main menu at the top to one containing rsgislib.**\n",
    "\n",
    "The following will use the basic registration, which is a simplified form of the proposed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsgislib import imageregistration\n",
    "\n",
    "# The reference image\n",
    "refImage = path.join(workdir,\"SR2\", \"Pass1\", \"OUTPUT\", \"Moasaic.tif\"\n",
    "                     \n",
    "# The floating image\n",
    "fImage = path.join(workdir,\"SR1\", \"Pass1\", \"OUTPUT\", \"Moasaic.tif\" \n",
    "                   \n",
    "# These are default values which work for this example \n",
    "pixelGap = 50\n",
    "threshold = 0.4\n",
    "window = 100\n",
    "search = 5\n",
    "stddevRef = 2\n",
    "stddevFloat = 2\n",
    "subpixelresolution = 4\n",
    "                   \n",
    "metric = imageregistration.METRIC_CORELATION\n",
    "outputType = imageregistration.TYPE_RSGIS_IMG2MAP\n",
    "                   \n",
    "tiepoints = path.join(workdir, \"tiepoints.txt\")\n",
    "\n",
    "# generate the tie points\n",
    "imageregistration.basicregistration(refImage, fImage, pixelGap, threshold, \n",
    "                                    window, search, stddevRef, stddevFloat, \n",
    "                                    subpixelresolution, metric,\n",
    "                                    outputType, tiepoints)\n",
    "\n",
    "# output image                   \n",
    "outRas = path.join(workdir,'RReNir_nnwp.tif'\n",
    "                   \n",
    "# warp the RReNir image\n",
    "imageregistration.nnwarp(fImage, output, outRas, wkt, 0.08, gdalformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
